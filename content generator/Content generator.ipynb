{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = {\n",
    "    'model': 'llama3.1',\n",
    "    'base_url': 'http://localhost:11434/v1',\n",
    "    'api_key': 'ollama',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to generate a story within 100 words'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = input(\"What do you want to generate today? \")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tokens: ['I', 'want', 'to', 'generate', 'a', 'story', 'within', '100', 'words']\n",
      "Lemmatized Tokens: want generate story within 100 word\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation = string.punctuation\n",
    "input_string = prompt\n",
    "tokens = word_tokenize(input_string)\n",
    "prompt = \" \".join([lemmatizer.lemmatize(token, pos='v') \n",
    "                                  for token in tokens \n",
    "                                  if token.lower() not in stop_words and token not in punctuation])\n",
    "print(\"Original Tokens:\", tokens)\n",
    "print(\"Lemmatized Tokens:\", prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_assistant = autogen.ConversableAgent(\n",
    "    'assistant', \n",
    "    system_message=f'I am here to intiate the chat',\n",
    "    llm_config=config_list, \n",
    "    human_input_mode='NEVER',\n",
    "    code_execution_config=False\n",
    ")\n",
    "\n",
    "text_assistant1 = autogen.ConversableAgent(\n",
    "    'assistant', \n",
    "    system_message=f'{prompt}',\n",
    "    llm_config=config_list, \n",
    "    human_input_mode='NEVER',\n",
    "    code_execution_config=False\n",
    ")\n",
    "\n",
    "evaluation_agent_1 = autogen.ConversableAgent(\n",
    "    'evaluation-agent-1',\n",
    "    system_message=f'You have to validate if the generated content is according to the {prompt}. Just reply with \"validated\" or \"not validated\".',\n",
    "    llm_config=config_list,\n",
    "    human_input_mode='NEVER',\n",
    "    code_execution_config=False,\n",
    ")\n",
    "\n",
    "evaluation_agent_2 = autogen.ConversableAgent(\n",
    "    'evaluation-agent-2',\n",
    "    system_message='Rate the content on a scale of 1 to 10 for clarity, accuracy, and creativity.',\n",
    "    llm_config=config_list,\n",
    "    human_input_mode='NEVER',\n",
    "    code_execution_config=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current conversation state: 1\n"
     ]
    }
   ],
   "source": [
    "conversation_state = 1\n",
    "speakers = []\n",
    "conversation_log=[]\n",
    "\n",
    "print(f\"Current conversation state: {conversation_state}\")\n",
    "\n",
    "\n",
    "def content_generation_func(speaker: autogen.AssistantAgent, groupchat: autogen.GroupChat):\n",
    "    global conversation_state\n",
    "    \n",
    "    print(f\"Current speaker: {speaker.name}, Conversation state: {conversation_state}\")\n",
    "    conversation_log.append({'agent': speaker.name, 'message': \"Message from \" + speaker.name})\n",
    "    \n",
    "    if conversation_state == 1:\n",
    "        if speaker == text_assistant:\n",
    "            \n",
    "            conversation_state += 1\n",
    "            speakers.append(text_assistant1.name)\n",
    "            return text_assistant1  \n",
    "        \n",
    "    \n",
    "    elif conversation_state == 2:\n",
    "        if speaker == text_assistant1:\n",
    "            \n",
    "            conversation_state += 1\n",
    "            speakers.append(evaluation_agent_1.name)\n",
    "            return evaluation_agent_1  \n",
    "    \n",
    "    elif conversation_state == 3:\n",
    "        if speaker == evaluation_agent_1:\n",
    "            \n",
    "            speakers.append(evaluation_agent_2.name)\n",
    "            print(\"Would you like to generate the story again? (yes or no)\")\n",
    "            user_input = input().strip().lower()  \n",
    "\n",
    "            if user_input == 'yes':\n",
    "                print(\"Regenerating the story...\")\n",
    "                conversation_state = 1\n",
    "                speakers.clear()  \n",
    "                return text_assistant  \n",
    "            else:\n",
    "                print(\"Thank you! Ending the conversation.\")\n",
    "                conversation_state += 1\n",
    "                return evaluation_agent_2  \n",
    "\n",
    "        \n",
    "    elif conversation_state == 4:\n",
    "        if speaker == evaluation_agent_1:\n",
    "           conversation_state += 1\n",
    "           return None  \n",
    "\n",
    "    else:\n",
    "        print(\"Unexpected state or speaker.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33massistant\u001b[0m (to chat_manager):\n",
      "\n",
      "want generate story within 100 word\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Current speaker: assistant, Conversation state: 1\n",
      "\u001b[32m\n",
      "Next speaker: assistant\n",
      "\u001b[0m\n",
      "\u001b[33massistant\u001b[0m (to chat_manager):\n",
      "\n",
      "Here's a 100-word story:\n",
      "\n",
      "As the sun set over the ocean, a young girl named Luna gathered seashells on the beach. She loved listening to her grandmother's stories about mermaids and sea sirens that sang in harmony with the waves. As she walked along the shoreline, Luna stumbled upon a shimmering shell with a note attached to it. The note read: \"For Luna, follow the tide.\" She looked out at the water and saw a glimpse of turquoise. Without hesitation, she dove into the ocean, following the tide that whispered secrets only she could hear.\n",
      "\n",
      "(Finished!)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Current speaker: assistant, Conversation state: 2\n",
      "\u001b[32m\n",
      "Next speaker: evaluation-agent-1\n",
      "\u001b[0m\n",
      "\u001b[33mevaluation-agent-1\u001b[0m (to chat_manager):\n",
      "\n",
      "validated\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Current speaker: evaluation-agent-1, Conversation state: 3\n",
      "Would you like to generate the story again? (yes or no)\n",
      "Thank you! Ending the conversation.\n",
      "\u001b[32m\n",
      "Next speaker: evaluation-agent-2\n",
      "\u001b[0m\n",
      "\u001b[33mevaluation-agent-2\u001b[0m (to chat_manager):\n",
      "\n",
      "Here's my rating:\n",
      "\n",
      "**Clarity:** 8/10 (The story is easy to follow, but some details like Luna's grandmother's stories might be lost on readers who don't understand their significance.)\n",
      "\n",
      "**Accuracy:** N/A (The story doesn't require factual accuracy)\n",
      "\n",
      "**Creativity:** 9/10 (The tale of a young girl following the tide to hear secrets from the ocean is an imaginative and engaging narrative.)\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "content_generation_chat = autogen.GroupChat(\n",
    "    agents=[text_assistant,text_assistant1, evaluation_agent_1, evaluation_agent_2],\n",
    "    speaker_selection_method=content_generation_func,\n",
    "    messages=[],  \n",
    "    max_round=4\n",
    ")\n",
    "\n",
    "content_generation_manager = autogen.GroupChatManager(\n",
    "    groupchat=content_generation_chat, llm_config=config_list\n",
    ")\n",
    "\n",
    "user_message = f\"{prompt}\"\n",
    "\n",
    "generated_content = text_assistant.initiate_chat(\n",
    "    content_generation_manager,\n",
    "    message=user_message\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
